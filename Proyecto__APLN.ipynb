{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3498d4ef5b224d00b0e6b81b4daa2859": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2c23079af96f4119ae9bcb24192fce77",
              "IPY_MODEL_61063797fe5342a5aec74e0239bffb87",
              "IPY_MODEL_0b302ba49614409d94408606c62b6fb3"
            ],
            "layout": "IPY_MODEL_db8737e39c06467c8f3a85ba3662581d"
          }
        },
        "2c23079af96f4119ae9bcb24192fce77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58762e02a6d84beba7b0ee02465ef587",
            "placeholder": "​",
            "style": "IPY_MODEL_8e32b5cef8bc4a2696f09ac180ad0039",
            "value": "Map: 100%"
          }
        },
        "61063797fe5342a5aec74e0239bffb87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd741946c0c945e4a9657442e9265d91",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3c538542fafe48a8ae3ef06295b1dabc",
            "value": 500
          }
        },
        "0b302ba49614409d94408606c62b6fb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a74bafa1841b4445a0f26d3759111523",
            "placeholder": "​",
            "style": "IPY_MODEL_2a04f95b41464f149959b6dd005f1b0d",
            "value": " 500/500 [00:23&lt;00:00, 21.58 examples/s]"
          }
        },
        "db8737e39c06467c8f3a85ba3662581d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58762e02a6d84beba7b0ee02465ef587": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e32b5cef8bc4a2696f09ac180ad0039": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd741946c0c945e4a9657442e9265d91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c538542fafe48a8ae3ef06295b1dabc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a74bafa1841b4445a0f26d3759111523": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a04f95b41464f149959b6dd005f1b0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "66a2f743e83343168e279ed9161f8ac9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3f5b192ed9f4445b984d66938ea29d62",
              "IPY_MODEL_abfdc76786904da3b30c248e559173d5",
              "IPY_MODEL_013af5390bfc472daa7a1a4bccd78237"
            ],
            "layout": "IPY_MODEL_320faa92b1404a2c80eeace6df083fe8"
          }
        },
        "3f5b192ed9f4445b984d66938ea29d62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dcd2961502124669b5ed0803191ec00a",
            "placeholder": "​",
            "style": "IPY_MODEL_bb9393c5967e4e0db551a8e89f7703f1",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "abfdc76786904da3b30c248e559173d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15288f0748c14d64a4b7fc16fb5b6252",
            "max": 44,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bc0da7adc3594ff58d644c771dddb4ec",
            "value": 44
          }
        },
        "013af5390bfc472daa7a1a4bccd78237": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94c2c9ee194949549fe87e677c20e0bc",
            "placeholder": "​",
            "style": "IPY_MODEL_247e61a2dd534d82959f8effd17a1b49",
            "value": " 44.0/44.0 [00:00&lt;00:00, 1.46kB/s]"
          }
        },
        "320faa92b1404a2c80eeace6df083fe8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dcd2961502124669b5ed0803191ec00a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb9393c5967e4e0db551a8e89f7703f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "15288f0748c14d64a4b7fc16fb5b6252": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc0da7adc3594ff58d644c771dddb4ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "94c2c9ee194949549fe87e677c20e0bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "247e61a2dd534d82959f8effd17a1b49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "77c7dfc0bfac4a428804e6e3cf7fbdeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0961287606804b71b03d55d9659163b9",
              "IPY_MODEL_26eb8d7f129642efb965b1d6c8218611",
              "IPY_MODEL_8e4929b8b3ef43dda0278500889fa0fb"
            ],
            "layout": "IPY_MODEL_5b54d7cddd824804bd5afa5268273854"
          }
        },
        "0961287606804b71b03d55d9659163b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9642289cf36e4e90b47b30a313abb91c",
            "placeholder": "​",
            "style": "IPY_MODEL_196fe1dd0f17413184cc8f6d95c840bd",
            "value": "source.spm: 100%"
          }
        },
        "26eb8d7f129642efb965b1d6c8218611": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_605432ea64a0481cac47b633556bc0d2",
            "max": 801636,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_88c4b0ff48a14c988017e0ae0eaebc5a",
            "value": 801636
          }
        },
        "8e4929b8b3ef43dda0278500889fa0fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f161bcf58937446398a08c7c7760d688",
            "placeholder": "​",
            "style": "IPY_MODEL_4d55aa77d0a74a63816346d81be4d2e1",
            "value": " 802k/802k [00:00&lt;00:00, 3.23MB/s]"
          }
        },
        "5b54d7cddd824804bd5afa5268273854": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9642289cf36e4e90b47b30a313abb91c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "196fe1dd0f17413184cc8f6d95c840bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "605432ea64a0481cac47b633556bc0d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88c4b0ff48a14c988017e0ae0eaebc5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f161bcf58937446398a08c7c7760d688": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d55aa77d0a74a63816346d81be4d2e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "05ecfe82f4ec49308725cce4d27ef754": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ee764b863ab84b01bf05acf5f5d190ec",
              "IPY_MODEL_35628a9190ae444a9d78a75c2e804bc6",
              "IPY_MODEL_f20c20cc59274a34a8952baeafa87bf7"
            ],
            "layout": "IPY_MODEL_6d822266d8cb42a392da93e19501036c"
          }
        },
        "ee764b863ab84b01bf05acf5f5d190ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_742ca5ee2e2c41cf8dbab36ab6e51c3a",
            "placeholder": "​",
            "style": "IPY_MODEL_172cb2bf30a449839215455b369b23fc",
            "value": "target.spm: 100%"
          }
        },
        "35628a9190ae444a9d78a75c2e804bc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f71d14c3150f4389ab1f754607e1d39f",
            "max": 825924,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b246dfc1546847efb036c6f2c88c5bf5",
            "value": 825924
          }
        },
        "f20c20cc59274a34a8952baeafa87bf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fbe0092fd3cf44d786d2571822fe0a6a",
            "placeholder": "​",
            "style": "IPY_MODEL_f894a8d8fa384ad094646e7cb89506a7",
            "value": " 826k/826k [00:00&lt;00:00, 9.67MB/s]"
          }
        },
        "6d822266d8cb42a392da93e19501036c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "742ca5ee2e2c41cf8dbab36ab6e51c3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "172cb2bf30a449839215455b369b23fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f71d14c3150f4389ab1f754607e1d39f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b246dfc1546847efb036c6f2c88c5bf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fbe0092fd3cf44d786d2571822fe0a6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f894a8d8fa384ad094646e7cb89506a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c9a1bc005774a08817cf2fd439f3b57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7bbcfb61f8974597a88613b602fa821e",
              "IPY_MODEL_72240e99259b4edda11d30e49fa81b28",
              "IPY_MODEL_25d1c0fc2e0c49128dfd91af67ccf90c"
            ],
            "layout": "IPY_MODEL_307ff6ab9e0649058f84a5c6461c7b9d"
          }
        },
        "7bbcfb61f8974597a88613b602fa821e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1254f98b9fdb4f0e9f3e2ccd2d8f8b36",
            "placeholder": "​",
            "style": "IPY_MODEL_e5abe675135841199e64a3a8a31458cd",
            "value": "vocab.json: 100%"
          }
        },
        "72240e99259b4edda11d30e49fa81b28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f30a8b2bf8b4795a769f810ee1adf5f",
            "max": 1590040,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9a93379de821475f990f270422cc2021",
            "value": 1590040
          }
        },
        "25d1c0fc2e0c49128dfd91af67ccf90c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0e0f90ef2d84f128c88315ff237bbe9",
            "placeholder": "​",
            "style": "IPY_MODEL_bbc4d5815ef3464ea2518b9238debb0c",
            "value": " 1.59M/1.59M [00:00&lt;00:00, 4.88MB/s]"
          }
        },
        "307ff6ab9e0649058f84a5c6461c7b9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1254f98b9fdb4f0e9f3e2ccd2d8f8b36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5abe675135841199e64a3a8a31458cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f30a8b2bf8b4795a769f810ee1adf5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a93379de821475f990f270422cc2021": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c0e0f90ef2d84f128c88315ff237bbe9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbc4d5815ef3464ea2518b9238debb0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "98cc3477e54a44f19b3df2f4ed9b85e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f2b6da2ea0ef4c4d9abf0588d2a9fb68",
              "IPY_MODEL_f7a6f668a7334bbcb24e350c27d3a666",
              "IPY_MODEL_ff4faecab7364f8b8725367c7139488c"
            ],
            "layout": "IPY_MODEL_b2ec9a0c13e74f4ea63fc8a3768192b8"
          }
        },
        "f2b6da2ea0ef4c4d9abf0588d2a9fb68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e21e07e6603b456aad1699e33967b654",
            "placeholder": "​",
            "style": "IPY_MODEL_3c1f30178c2f4eea9957596cf317477f",
            "value": "config.json: 100%"
          }
        },
        "f7a6f668a7334bbcb24e350c27d3a666": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a17b4e26312140e2be2a7cea443d19da",
            "max": 1473,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ec15dce1d6364c7183c1979c85659eea",
            "value": 1473
          }
        },
        "ff4faecab7364f8b8725367c7139488c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dbf01be89a2c4e21bd7216a28f1d6576",
            "placeholder": "​",
            "style": "IPY_MODEL_088edc0cb0d942d482a76e1525856f93",
            "value": " 1.47k/1.47k [00:00&lt;00:00, 27.2kB/s]"
          }
        },
        "b2ec9a0c13e74f4ea63fc8a3768192b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e21e07e6603b456aad1699e33967b654": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c1f30178c2f4eea9957596cf317477f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a17b4e26312140e2be2a7cea443d19da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec15dce1d6364c7183c1979c85659eea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dbf01be89a2c4e21bd7216a28f1d6576": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "088edc0cb0d942d482a76e1525856f93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f8d735172e246719c9cf65111531556": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7720d097c5aa4def950421319a2cad36",
              "IPY_MODEL_95187b5c8e794697874275805d90f42d",
              "IPY_MODEL_dc61d55d20254121bb6a59ac50a5ca6c"
            ],
            "layout": "IPY_MODEL_60cc7a26fa5d4a7796a28e961133ed6d"
          }
        },
        "7720d097c5aa4def950421319a2cad36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60cb1e913e624324abab7d3303c18484",
            "placeholder": "​",
            "style": "IPY_MODEL_4157f74be2804e83beccfa5117b660ee",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "95187b5c8e794697874275805d90f42d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f38be5a866c04da9ab40b107ea64b5f7",
            "max": 312087523,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8741010dd51f46eeb078b97d1278367e",
            "value": 312087523
          }
        },
        "dc61d55d20254121bb6a59ac50a5ca6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df7f5d9ef0474b0f99687a08929b0ed3",
            "placeholder": "​",
            "style": "IPY_MODEL_a6ec715beb76484da71423c12600ff6a",
            "value": " 312M/312M [00:01&lt;00:00, 223MB/s]"
          }
        },
        "60cc7a26fa5d4a7796a28e961133ed6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60cb1e913e624324abab7d3303c18484": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4157f74be2804e83beccfa5117b660ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f38be5a866c04da9ab40b107ea64b5f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8741010dd51f46eeb078b97d1278367e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "df7f5d9ef0474b0f99687a08929b0ed3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6ec715beb76484da71423c12600ff6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e0ba43159cac424c962b80f532e876e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3f4e0c2ee5a24db69b79e0c3f1a71b43",
              "IPY_MODEL_d889ffd1fc1c4449bd844907d9adc56c",
              "IPY_MODEL_2e23ff9984f34439a3fb789424d10f04"
            ],
            "layout": "IPY_MODEL_0c30e87a69954a6eb61baee16e9e3d47"
          }
        },
        "3f4e0c2ee5a24db69b79e0c3f1a71b43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc09dc1815c24ff797386dab5c68ff63",
            "placeholder": "​",
            "style": "IPY_MODEL_e505a2344ad344c2ba877c699d328e81",
            "value": "generation_config.json: 100%"
          }
        },
        "d889ffd1fc1c4449bd844907d9adc56c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e3ecffe468a42a9842fba6afc6e3f29",
            "max": 293,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_409905e1b84d43b38af6ad09d1503507",
            "value": 293
          }
        },
        "2e23ff9984f34439a3fb789424d10f04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9f2464d91ad4490b213899e3624fab3",
            "placeholder": "​",
            "style": "IPY_MODEL_c691132db5c74ad0a60b3d34362ef33d",
            "value": " 293/293 [00:00&lt;00:00, 16.6kB/s]"
          }
        },
        "0c30e87a69954a6eb61baee16e9e3d47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc09dc1815c24ff797386dab5c68ff63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e505a2344ad344c2ba877c699d328e81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e3ecffe468a42a9842fba6afc6e3f29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "409905e1b84d43b38af6ad09d1503507": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c9f2464d91ad4490b213899e3624fab3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c691132db5c74ad0a60b3d34362ef33d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f71f5ece040248aa8b0d7df0250513c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_01686a4dd78a4defb5e58afac15789c2",
              "IPY_MODEL_1ba419bf100d4320ba4f74665230b552",
              "IPY_MODEL_a3fc7ad0bdac4f80ae1eeb13778fa246"
            ],
            "layout": "IPY_MODEL_45f3396f3b7c4bf6a6c3a01a6fc59a5e"
          }
        },
        "01686a4dd78a4defb5e58afac15789c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a921fb796e654816adee709d63ba6092",
            "placeholder": "​",
            "style": "IPY_MODEL_f893ceb86906464897ae56086527ba1b",
            "value": "Map: 100%"
          }
        },
        "1ba419bf100d4320ba4f74665230b552": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ca5969d219e485cb0c7c2138b8e65e4",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e2a84a7e2c784f8e818a05eb7e4789bc",
            "value": 500
          }
        },
        "a3fc7ad0bdac4f80ae1eeb13778fa246": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2db2b508dd3845448169d4ead9ebd7f6",
            "placeholder": "​",
            "style": "IPY_MODEL_40b57c6694374672919e1e410e8f38c1",
            "value": " 500/500 [00:44&lt;00:00, 11.32 examples/s]"
          }
        },
        "45f3396f3b7c4bf6a6c3a01a6fc59a5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a921fb796e654816adee709d63ba6092": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f893ceb86906464897ae56086527ba1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ca5969d219e485cb0c7c2138b8e65e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2a84a7e2c784f8e818a05eb7e4789bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2db2b508dd3845448169d4ead9ebd7f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40b57c6694374672919e1e410e8f38c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Proyecto: Sistema Generador de Resúmenes\n",
        "\n",
        "## Descripción\n",
        "Este proyecto se centra en el desarrollo de un sistema automatizado para la generación de resúmenes abstractivos de artículos científicos.  \n",
        "El objetivo principal es reducir la extensión de textos académicos largos, organizando la información en secciones clave. De esta manera, los usuarios podrán acceder rápidamente a los puntos más relevantes, optimizando el tiempo dedicado a la lectura y análisis de textos técnicos y científicos.\n",
        "\n",
        "## Autores\n",
        "- Oscar Alberto Sánchez Martinez\n",
        "- Octavio Ortega Hernández\n",
        "- De La Fuente Cuamatzi Jesus\n",
        "- Becerra Tapia Alberto"
      ],
      "metadata": {
        "id": "EFNlusgKz9JM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Extraccion de texto 1 usando OCR\n"
      ],
      "metadata": {
        "id": "F3rkNHvmFa79"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## librerias necesarias para teseract\n",
        "!sudo apt-get install tesseract-ocr\n",
        "!pip install pytesseract pdf2image opencv-python-headless pillow\n",
        "!sudo apt-get install poppler-utils\n"
      ],
      "metadata": {
        "id": "blv-9Q3pLvnD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebd562fd-4e66-4d9b-9a85-6defd17a19de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 4,816 kB of archives.\n",
            "After this operation, 15.6 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-eng all 1:4.00~git30-7274cfa-1.1 [1,591 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-osd all 1:4.00~git30-7274cfa-1.1 [2,990 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr amd64 4.1.1-2.1build1 [236 kB]\n",
            "Fetched 4,816 kB in 1s (9,458 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 123632 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.1.1-2.1build1_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting pdf2image\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (11.0.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (24.2)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python-headless) (1.26.4)\n",
            "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: pytesseract, pdf2image\n",
            "Successfully installed pdf2image-1.17.0 pytesseract-0.3.13\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  poppler-utils\n",
            "0 upgraded, 1 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 186 kB of archives.\n",
            "After this operation, 696 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.5 [186 kB]\n",
            "Fetched 186 kB in 0s (1,085 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 123679 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.5_amd64.deb ...\n",
            "Unpacking poppler-utils (22.02.0-2ubuntu0.5) ...\n",
            "Setting up poppler-utils (22.02.0-2ubuntu0.5) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from pdf2image import convert_from_path\n",
        "import cv2\n",
        "import pytesseract\n",
        "from PIL import Image\n",
        "from google.colab import drive\n",
        "\n",
        "# Montar Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Función para preprocesar imágenes\n",
        "def preprocesar_imagen(imagen):\n",
        "    img = cv2.cvtColor(np.array(imagen), cv2.COLOR_RGB2GRAY)  # Convertir a escala de grises\n",
        "    img = cv2.GaussianBlur(img, (5, 5), 0)  # Desenfoque gaussiano\n",
        "    _, img_binaria = cv2.threshold(img, 128, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)  # Binarización\n",
        "    img_denoised = cv2.fastNlMeansDenoising(img_binaria, h=30)  # Reducir ruido\n",
        "    return img_denoised\n",
        "\n",
        "# Función para extraer texto de una imagen\n",
        "def extraer_texto_de_imagen(imagen):\n",
        "    texto = pytesseract.image_to_string(imagen, lang='eng')  # Usar idioma inglés\n",
        "    return texto\n",
        "\n",
        "# Pipeline principal\n",
        "def procesar_pdf_a_texto(ruta_pdf):\n",
        "    print(\"Convirtiendo PDF a imágenes en memoria...\")\n",
        "    imagenes = convert_from_path(ruta_pdf, dpi=300, fmt='png')\n",
        "    texto_extraido = []\n",
        "\n",
        "    for i, imagen in enumerate(imagenes):\n",
        "        print(f\"Preprocesando imagen de página {i+1}...\")\n",
        "        imagen_procesada = preprocesar_imagen(imagen)\n",
        "        texto = extraer_texto_de_imagen(imagen_procesada)\n",
        "        texto_extraido.append(texto)\n",
        "\n",
        "    return texto_extraido\n",
        "\n",
        "\n",
        "ruta_pdf = '/content/articulo_3.pdf'\n",
        "\n",
        "# Procesar PDF y obtener texto\n",
        "todo_el_texto = procesar_pdf_a_texto(ruta_pdf)\n",
        "\n",
        "# Ruta de salida para guardar el archivo de texto en Google Drive\n",
        "dir_salida = '/content/drive/My Drive/imagenes'\n",
        "os.makedirs(dir_salida, exist_ok=True)\n",
        "output_path = os.path.join(dir_salida, \"output_text_prueba4.txt\")\n",
        "\n",
        "# Guardar el texto extraído en un archivo\n",
        "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    for num_pagina, texto_pagina in enumerate(todo_el_texto, start=1):\n",
        "        f.write(f\"--- Página {num_pagina} ---\\n\")\n",
        "        f.write(texto_pagina + \"\\n\")\n",
        "print(\"Texto extraído y guardado en Drive\")\n"
      ],
      "metadata": {
        "id": "fltVhHOwFd8Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3edd2fe0-7f3e-4db2-fed7-e90fe81720ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Convirtiendo PDF a imágenes en memoria...\n",
            "Preprocesando imagen de página 1...\n",
            "Preprocesando imagen de página 2...\n",
            "Preprocesando imagen de página 3...\n",
            "Preprocesando imagen de página 4...\n",
            "Preprocesando imagen de página 5...\n",
            "Preprocesando imagen de página 6...\n",
            "Preprocesando imagen de página 7...\n",
            "Preprocesando imagen de página 8...\n",
            "Texto extraído y guardado en Drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Extracción de texto 2 usando NLP"
      ],
      "metadata": {
        "id": "jXjsjvihzcQK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2\n",
        "\n",
        "# Cargar bibliotecas\n",
        "import PyPDF2\n",
        "import re\n",
        "import os\n",
        "\n",
        "# Paso 1: Función para extraer texto de un PDF\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    text = \"\"\n",
        "    with open(pdf_path, 'rb') as file:\n",
        "        reader = PyPDF2.PdfReader(file)\n",
        "        for page in reader.pages:\n",
        "            text += page.extract_text() + \"\\n\"\n",
        "    return text\n",
        "\n",
        "# Paso 2: Función para limpiar el texto\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'\\$.*?\\$', '', text)  # Eliminar fórmulas matemáticas\n",
        "    text = re.sub(r'\\\\\\[.*?\\\\\\]', '', text)  # Eliminar expresiones entre corchetes\n",
        "    text = re.sub(r'[^\\w\\s.,;:()\\-]', '', text)  # Eliminar caracteres especiales\n",
        "    text = re.sub(r'\\s+', ' ', text)  # Reemplazar espacios múltiples por uno solo\n",
        "    return text.strip()\n",
        "\n",
        "# Paso 3: Función principal para procesar el PDF\n",
        "def process_pdf(pdf_path):\n",
        "    text = extract_text_from_pdf(pdf_path)\n",
        "    return clean_text(text)\n",
        "\n",
        "# Paso 4: Ejecución principal simplificada\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    pdf = \"/content/articulo_3.pdf\"\n",
        "    print(\"Texto limpio:\\n\")\n",
        "    print(process_pdf(pdf))\n"
      ],
      "metadata": {
        "id": "9X7bBtnWuCK6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b71f63d-86c7-4eb4-c53e-20d68ba94340"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n",
            "Texto limpio:\n",
            "\n",
            "Using Chinese Glyphs for Named Entity Recognition Arijit Sehanobishy Yale University arijit.sehanobishyale.eduChan Hee Songy University of Notre Dame csong1nd.edu Abstract Most Named Entity Recognition (NER) systems use addi- tional features like part-of-speech (POS) tags, shallow pars- ing, gazetteers, etc. Adding these external features to NER systems have been shown to have a positive impact. How- ever, creating gazetteers or taggers can take a lot of time and may require extensive data cleaning. In this work instead of using these traditional features we use lexicographic features of Chinese characters. Chinese characters are composed of graphical components called radicals and these components often have some semantic indicators. We propose CNN based models that incorporate this semantic information and use them for NER. Our models show an improvement over the baseline BERT-BiLSTM-CRF model. We present one of the ﬁrst studies on Chinese OntoNotes v 5:0and show an im- provement of :64F1 score over the baseline. We present a state-of-the-art (SOTA) F1 score of 71:81on the Weibo dataset, show a competitive improvement of 0 :72over baseline on the ResumeNER dataset, and a SOTA F1 score of96:49on the MSRA dataset. 1 Introduction Augmenting named entity recognition (NER) systems with additional features like gazetteers, bag of words or char- acter level information has been commonplace like Sang and Meulder (2003), Collobert et al. (2011) and Chiu and Nichols (2016). Over the years these added features have shown to improve the NER systems. We follow this ap- proach to the Chinese NER task. Chinese is a logographic language and many Chinese characters have evolved from pictures, thus we incorporate the semantic information from the pictures of the Chinese characters which can be used as an added feature for Chinese NER systems. Several au- thors Shi et al. (2015), Li et al. (2015), Sun et al. (2014) and Meng et al. (2019) managed to use the radical representa- tions successfully in a wide range of natural language under- standing (NLU) tasks. However using these images for NLU have sometimes proved to be a challenge. For example Liu et al. (2017), and Zhang and LeCun (2017) work shows in- consistent results and some even yield negative results (Dai equal contribution yWork done during SCALE program at JHUand Cai 2017). Furthermore, there has not been a lot of work in using glyphs particularly for NER. Only recently, Meng et al. (2019) presented a complex Glyph reinforced model that concatenates glyph embeddings with BERT (Devlin et al. 2018) embeddings. In this paper, we present a new kind of glyph-augmented architecture that is easier to implement and train, more robust and requires less data. We show that our models have a signiﬁcant improvement over our base- line on two datasets, Chinese OntoNotes v 5:0(Pradhan and Ramshaw 2017) and Weibo (Peng and Dredze 2015). We approach the problem of incorporating Chinese glyphs as an image classiﬁcation problem and present two CNNs which we call strided and GLYNN inspired from computer vision. We treat this encoding problem purely in terms of computer vision, i.e. to extract meaningful fea- tures from the image, instead of a specialized CNN that en- capsulates the subtle radicals. Both CNNs are used to en- code the glyphs and these encoded images are then used as an added feature for our NER system. We also present an autoencoder architecture to pretrain GLYNN and compare the results. Due to treating the problem as an image classi- ﬁcation problem, our models are easier to train and imple- ment. Since the OntoNotes v 5:0and Weibo datasets have a signiﬁcant number of non-Chinese characters in them, we also show our model is robust by conducting a robustness test of our systems by throwing in the pictures of the non- Chinese characters as well pictures of English alphabets and show that it still beats the baseline model. English alpha- bets unlike Chinese have no semantic information so we can think of these added pictures as noise. Furthermore, unlike Meng et al. (2019) who used extensive dataset of Chinese glyphs gathered from different sources, we use only about 4500 grayscale 64x64Chinese characters in Hei Ti font. Hei Ti font, similar to sans-serif, is widely used and is easy to gather glyph information. This enables us to use a lot less data to train our model. In this paper, we found that all our models are an improvement over the baseline and achieve state of the art F1 score on the Weibo dataset. Our code can be found in https:github.comarijitthegameBERT-CNN- models. The main strength of our model is as follows: Easy to implement and train Robust to non-Chinese languages in the dataset Requires less amount of glyph data to train 2 Architecture of our GLYPH models BERT is the state of the art language model introduced by Devlin et al. (2018). BERT is a transformer based model which is trained on masked word prediction and next sen- tence prediction tasks and is trained on Wikipedia data and a large book corpus. We use the Chinese BERT base which is released by Google and is publicly available on Google Github. We then combine BERT with a popular used ar- chitecture in NER, BiLSTM-CRF as in Huang, Xu and Yu (2015), Ma and Hovy (2016), Chiu and Nichols (2016) and Zhang and Yang (2018). Our model (ﬁgure 1) consists of the following parts: pre- trained BERT embeddings and the (pretrained) CNN embed- dings. We concatenate the last four layers of BERT and the CNN vectors which are our new character embeddings. We then feed these character embeddings to the BiLSTM layer which are ﬁnally decoded via a CRF layer. The CNN- LSTM-CRF is then being trained end-to-end while we keep BERT frozen. Thus we try to take advantage of BERTs large pre-scale training and the information from Chinese glyphs encoded by our CNNs. Figure 1: Architecture of our Glyph Models The selection of the CNNs are primarily motivated by problems in computer vision. The convolution layers are the key in extracting meaningful features and one needs at least two to extract meaningful features. Batch normaliza- tion (Ioffe and Szegedy 2015) and layer normalizations (Ba, Kiros and Hinton 2016) are generally used to accelerate training. To vindicate our choice of these CNNs we applied them to Fashion MNIST dataset and we got around 93 accuracy. 2.1 Obtaining Glyph information Before giving a detailed description of the CNNs used to extract glyph features we want to explain how the model is trained. All the datasets used in this paper are character tok- enized and in IOB or BIOES format. We construct a dictio-nary of 4200 Chinese characters where the key is the UTF- 8 codepoint and the value is the numpy array of pixels. A char- acter in each line is one of the following types: Chinese character and one of the 4200 characters we used: We look up its image via our dictionary using its UTF- 8 codepoint and pass the image through our CNN (strided or GLYNN, depending on the model). Out of vocabulary Chinese characters (there are about a hundred of them across various datasets): Since we dont have that characters picture we use a black image, i.e. 64x64pixel of all 1s and then pass the black image through the CNN. Non Chinese character: we use a white image, i.e. 64x64 pixel of all 0s and pass it through our CNN. In each of the above cases, we then get the BERT output of the character and concatenate the BERT output with the output of the CNN. These concatenated vectors are our char- acter representations. 2.2 Strided CNN This CNN is inspired from the work of Su and Lee (2017) who used 5convolution layers. They used their CNN for Chinese word analogy problems. We did an ablation study and adapted a smaller CNN for our model. Figure 2 is the picture of our strided CNN. This consists of 4 2D convo- lution layers with strides 2, ﬁlter size of 64, kernel size of 3and activation leaky ReLU. Then we have a Flatten layer and a Dense layer of output dimension 64. Furthermore we normalize the ﬁnal output by using layer normalization as introduced by Ba, Kiros, and Hinton (2016). Figure 2: Strided CNN encoder 2.3 GLYNN CNN In this subsection we describe another CNN which we call Glynn to encode the glyphs. The idea for this CNN comes purely from image classiﬁcation tasks. The convolution lay- ers are the most important component of CNN and one needs at least 2layers to capture details of an image. Batch normal- ization (Ioffe and Szegedy 2015) is used to speed up train- ing and the dropout layers are used to prevent overﬁtting and the maxpooling layers are used to reduce the computational Figure 3: GLYNN CNN Encoder complexity of the network. Figure 3 is the picture of our CNN. We use ﬁlter size of 32, kernel size of 3and paddingsame in both the convolution layers, while we use sigmoid activation and strides (2;2)for our ﬁrst convo- lution layer and ReLU activation and strides (1;1)for the second convolution layer. For both the maxpooling layers we use a pool size of 2. And ﬁnally we use two dropout layers. The output dimension of the CNN is 256. We pretrain the CNN using an autoencoder shown in ﬁgure 4. Figure 4: Autoencoder 2.4 Autoencoder We also employ autoencoder (Zhou et al. 2015) to pre- train the CNN. The main purpose of the autoencoder is di-mensionality reduction, i.e. the autoencoder encourages the CNN to extract high level features without employing multi- ple convolution layers like the strided CNN. A deep autoen- coder architecture is a multi-layer neural network that tries to reconstruct its input. The architecture therefore consists of a sequence of Nencoder layers followed by a sequence of Ndecoder layers. Let :fi;1iNgbe the param- eters of each layer, where each ican be further written as ifWi e; bi e; Wi d; bi dg, where Wi e; bi eare the weights and the biases of the i-encoder layer and Wi d; bi dare the weights and the biases of the i-decoder layer. If x2Rdbe an input, then the encoder-decoder architecture can be formulated by the following series of equations. h0:x; hifi e(hi1) :si e(Wi ehi1bi e); hn r:hn; hi rfi d(hi1) :si d(Wi dhi1 rbi e)(1) where fi eandfi dare the encoding and decoding functions andsi e(resp. si d) are elementwise non-linear functions and h1 r2Rd. The training objective is to ﬁnd a set of parameters opt:fWe;be;Wd;bdgwhich will minimize the recon- struction error over all points in the dataset D, i.e. L:1 jDjX x2Djjxh1 r(x)jj2 2 (2) andjjjj is the usual L2-norm in Rd. We train the autoencoder for 200 epochs and we use RMSprop as our optimizer. In the GLYNN CNN we take the encoder part of the au- toencoder, 3 Related Works Our work follows the mainstream approach to named en- tity recognition. Mainstream neural approach predates to 2003 when Hammerton (2003) used Long Short-Term Mem- ory for NER, achieving just above average for English F1 scores and improvement for German NER. Hochreiter and Schmidhuber (1997) presented Long Short-Term Memory (LSTM), and it was expanded by Gers, Schmidhuber and Cummings (2000), and reached its current form by Graves and Schmidhuber (2005). LSTM is increasing in its use with NER problems over the past 2decades. Recent works in NER follows this approach, mainly using BiLSTM- CRF architecture. Bi-LSTM-CRF architecture was ﬁrst pro- posed by Huang, Xu and Yu (2015), and has been widely studied and augmented. Chiu and Nichols (2016) and Ma and Hovy (2016) augmented LSTM-CRF architecture with character-level convolutional neural network to add an addi- tional features to the architecture. Instead of applying convo- lutional neural network to the text, we apply it to the glyphs to augment our Bi-LSTM-CRF. Recently, transfer learning architectures has shown sig- niﬁcant improvement in various natural language process- ing tasks such as question answering, natural language un- derstanding, machine translation and natural language in- ference. Devlin et al. (2018) uses stacked bi-directional transformer layers called BERT that is trained on masked word prediction and next sentence prediction tasks. BERT is trained on over 3;300M words mostly gathered from Wikipedia. By employing a task-speciﬁc ﬁnal output layer, BERT can be tuned to many different natural language pro- cessing tasks. In this work, we apply BERT to NER and use BiLSTM-CRF as the output layer of BERT-CNN. Our approach presents an architecture that doesnt require a dataset-speciﬁc architecture and feature engineering. In the recent years there has been a lot of work to use Chinese glyphs as an added feature for various language un- derstanding tasks. Our work is similar to Meng et al (2019) but differs in many aspects. Unlike Meng et al, who uses ensemble of glyph images from different time periods and writers, which is often hard to collect. Instead we use only about 4500 grayscale 64x64Chinese characters in Hei Ti font. Hei Ti font, which is similar to sans-serif, is widely used and easy to collect glyph data. These are all the Chinese characters found in Chinese BERT vocabulary. Even though there are over 20;000CJK characters, we only have about a hundred of out-of-vocabulary characters in OntoNotes v 5:0 and Weibo. So that allowed us to use considerable less data than Meng et al. (2019). Another major difference between our approach and all the aforementioned authors in the in- troduction is that our CNNs are agnostic to the subtleties of Chinese characters and we treat this encoding problem with computer vision ideas and extract meaningful fea- tures from the image, instead of having a specialized CNN that encapsulates the subtle radicals. Both Su and Lee (2017) and Meng et al (2019) use autoencoders to pretrain their CNN. Su and Lee (2017) pretrain the CNN by freezing some layers while Meng et al (2019) pretrain the CNN with the objective of recovering an image id while we follow the approach of jointly training all layers of the CNN (Zhou et al. 2015) with the global objective of reconstructing the im- age. We also employ pretraining to GLYNN and shows that it has a performance gain compared to not pretraining. An- other difference between our architecture and the GLYCE model (Meng et al. 2019) is that we use a BiLSTM instead of a transformer to encode the BERT Glyph Embeddings. Overall, our model is a very robust and easy to train model that uses very little data for augmenting the glyph features and successfully marry techniques from computer vision and state of the art language models. 4 Experimental results 4.1 Datasets used We used Chinese OntoNotes v 5:0dataset compiled for CoNLL-2013 shared task (Pradhan and Ramshaw 2017) and follow the standard traindevtest split as presented in Prad- han et al. (2013). OntoNotes v 5:0is composed of 18differ- ent tag sets, ART, DAT, EVT, FAC, GPE, LAW, LNG, LOC, MON, NRP, NUM, ORD, ORG, PCT, PER, PRD, QTY and TIM. We chose OntoNotes v 5:0due to it being com- prehensive of previous OntoNotes releases. OntoNotes v 5:0 contains an extra genre, telephone communications, whichTrain Dev Test OntoNotes v 5:0 tok 1:2M 178K 149K ent 65K 9401 7785 sent 37K 6217 4293 Weibo tok 1855 379 405 ent 957 153 211 sent 1350 270 270 ResumeNER tok 124:1k13:9k15:1k ent 13:4k 1497 1630 sent 3:8k 0:46k0:48k MSRA tok 2169:9k - 172:6k ent 75k - 6:1k sent 46:4k - 4:4k Table 1: Statistics of the OntoNotes v 5:0, Weibo, MSRA and ResumeNER dataset, tokstands for number of tokens in each split, entstands for number of annotated entities in each split and sent stands for number of sentences in each split makes the dataset more representative of the real world. We also use Weibo dataset (Peng and Dredze 2015) and Re- sumeNER dataset (Zhang and Yang 2018) which has 4en- tity types: PER, ORG, GPE and LOC and 8entity types: CONT, EDU, LOC, NAME, ORG, PRO, RACE and TITLE respectively. We use both named entity mention and nomi- nal mentions for the Weibo dataset as well as Weibo with just the named entity mention which we refer to by Weibo NAM. MSRA dataset has 3entity types PER, LOC and ORG. Since MSRA do not have a dev set, we take 10 of the test set as our dev set. The statistics of datasets are shown in Table 1. We use the train set to train the model, the dev set for vali- dation and the test set for testing. All the results are results from the test set. 4.2 NER results on OntoNotes v 5:0, Weibo and ResumeNER To make a proper comparison, we run our vanilla BERT- LSTM-CRF models 10times on OntoNotes v 5:0and20 times on Weibo NAM and 40times on Weibo to establish a baseline. For better understanding of our results, in Ta- ble 2 we give a complete list of all hyperparameters used in running these experiments. We ran 10trials for 30epochs for each of Glynn CNN (default and higher dropout) and strided CNN on Chinese OntoNotes v 5:0. We also compare the statistical signiﬁcance of our results over the baseline by performing a 2-sample t- test. We call a result statistically signiﬁcant if the p-value is less than :05. We report our scores in Table 3. Using the F1 scores obtained by the Glynn CNN (dropout :5) and the strided CNN, we perform the 2- sample t-test and obtain a p-value of :001. Thus we see that strided CNN is a signiﬁcant improvement over both the BERT baseline and the GLYNN. But interestingly both the GLYNN models outperform strided on the dev sets. Finally we note that it is not a huge surprise that the gains are low on OntoNotes v 5:0 Hyperparameters Number of BiLSTM lay- ers1 Hidden size LSTM 256 dropout LSTM :5 optimizer adafactor clipgrad norm 1 learning rate scheduler cosine decay ﬁrst decay steps 1000 BERT layers used 4;3,2;1 weight decay :005 Default dropout in GLYNN CNN:3,:5resp. training epochs 30 mini batch size 8 Table 2: Default hyperparameters used in the experiments Models Avg Std dev Max p-value BERT-BiLSTM-CRF (baseline) 78:80 :33 79:09 NA GLYNN 79:24 :16 79:47 :004 GLYNN dropout .5 79:22 :13 79:35 :005 strided 79:59 :12 79:73 :001 Che et al. ( 2013 ) NA NA 69:82 NA Pappu et al. ( 2017 ) NA NA 67:2 NA Xu et al. ( 2017 ) NA NA 71:83 NA Nosirova et al. ( 2019 ) NA NA 72:12 NA Table 3: Results on OntoNotes v 5:0 as the dataset is big and we used a small amount of data to augment the system. Since the Weibo dataset is smaller and is noisier than OntoNotes v 5:0, we ran vanilla BERT-BiLSTM-CRF 20 times and 40times respectively on Weibo NAM and the Weibo dataset to establish a baseline. We ran 20trials for 30 epochs for each of Glynn CNN (default and higher dropout) and strided CNN on Weibo. We also calculate the p-value between our CNNs and the baseline BERT to see if our re- sults are statistically signiﬁcant. Table 4 gives us a summary of our results on Weibo and we compare our results with He and Sun (2017). Table 4 shows that Weibo experiment results from both CNNs are statistically signiﬁcant than the vanilla BERT. However p- value between strided CNN and GLYNN is :71, which shows that their performance on aver- age is statistically the same. Models Avg Std dev Max p-value BERT-BiLSTM-CRF (baseline) 69:9 1:4 71:8 NA GLYNN 71:44 1:48 73:9 :003 GLYNN dropout .5 71:34 1:2 73:36 :003 strided 71:34 1:48 73:35 :005 He and Xu (2017) 54:50 NA NA NA Zhu and Wang (2019) 55:38 NA NA NA Table 4: Results on Weibo NAM Table 5 shows our results on the full Weibo dataset. Even though strided CNN did not show any improvement, we made signiﬁcant gains with the GLYNN CNN over the base-line and set a new SOTA F1 score. Even though strided CNN shows improvement over the baseline on other datasets and the dev sets, we do not understand why it underperforms in this case. We would like to investigate this problem further. Models Avg Std dev Max p-value BERT-BiLSTM-CRF (baseline) 68:68 1:07 70:79 NA GLYNN 69:2 1:11 71:81 :03 GLYNN dropout .5 69:01 1:11 71:58 :18 strided 68:67 :97 70:7 :97 Meng et al. (2019) NA NA 67:6 NA Zhang and Yang (2018) NA NA 58:79 NA Table 5: Results on Full Weibo Table 6 shows our results on the ResumeNER dataset. We ran our experiments 15times and we hope a grid search will make our results closer to SOTA scores reported by Meng et al. (2019). We would also like to point out that we trained our models for 20epochs which seemed to give the best re- sults. Models Avg Std dev Max p-value BERT-BiLSTM-CRF (baseline) 94:92 :51 95:72 NA GLYNN 95:61 :62 96:49 :02 strided 95:66 :47 96:42 :01 Meng et al. (2019) NA NA 96:54 NA Zhang and Yang (2018) NA NA 94:46 NA Table 6: Results on ResumeNER Table 7 shows our results on MSRA. We ran 10trials for each experiment for 30epochs. Models Avg Std dev Max p-value BERT-BiLSTM-CRF (baseline) 95:05 :41 95:3 NA GLYNN 95:07 :48 96:49 :8 strided 95:21 :42 95:63 :67 Meng et al. (2019) NA NA 95:54 NA Zhang and Yang (2018) NA NA 93:18 NA Table 7: Results on MSRA 4.3 Robustness test 1 9of Chinese OntoNotes v 5:0and1 6of Weibo characters are not Chinese. So a natural question would be: what if we add the pictures of the other non-Chinese characters as well. To test the performance of the system, we added in an additional 3000 pictures. These are the pictures of all non CJK charac- ters found in the Chinese BERT vocabulary. Of course, a picture of an English character has no semantic meaning so adding these characters can be thought as a robustness test of our NER systems. However we do not change the number of Chinese characters used. Now the main differences are as follows: We construct a larger dictionary ( 8000 key-value pairs). If the characters codepoint is a key in our dictionary, we look up its image and pass through our CNN as before. If the codepoint is a non Chinese character and not a key, we then use the white image as before. If the codepoint is a Chinese character and not a key, then we use the black image as before. Over 200trials with various hyperparameters, we found that adding the pictures of non-Chinese characters drop the F1 scores but the models still beat the baseline model. In the tables 8, 9 we show a snippet of our results. The results in the Table 8 are compiled over 20trials running for 30epochs with the default hyperparameters as in Table 2. Models Avg Std dev Max GLYNN dropout :570:83 1:18 73:61 GLYNN 70:7 1:55 73:25 strided 70:7 1:6 73:81 Table 8: Results on Weibo NAM with added pictures However the difference in performance between GLYNN (with :5dropout) and strided is statistically insigniﬁcant as the p-value is :768. In the Table 9 below we show some our results on OntoNotes v 5:0compiled over 10trials running for 30 epochs with the default hyperparameters as in Table 2. Avg Std dev Max GLYNN dropout :579:31 :19 79:59 GLYNN 79:27 :04 79:33 strided 78:95 :26 79:21 Table 9: Results on OntoNotes v 5:0with added pictures We believe the reason for the diminished performance is due to the fact that the pictures of various extra characters do not have any semantic meaning unlike the Chinese charac- ters. So these pictures give a noisy signal to our NER system which in turn affects the performance. 4.4 Hyperparameter tuning In this subsection we will discuss other hyperparameters we try out during our experiments. Effects of learning rates and optimizers : We used Adam optimizer on OntoNotes v 5:0for5trials with the learning rates :001,:0005 and:0001 with early stopping if the loss did not decrease over 5 epochs. We obtained an average F1 scores of 77:8,76:64and77:72respectively. But in general, we found Adam performs poorly compared to Adafactor. Early stopping with all the above learning rates with both Adam and Adafactor on Weibo produced erratic results with extremely high standard deviations. Effects of dropout : We also used dropouts of :5on each the dropout layers of the Glynn CNN and ran multiple trials. Table 3 summarizes our results on OntoNotes v 5:0 after 10trials and we also compute the p-value to test the difference in the average performance of GLYNN. Changing the dropouts to :5did not have any statisticallysigniﬁcant improvement over the default hyperparameters on OntoNotes v 5:0and ResumeNER. We also ran 20trials on Weibo with this new dropout. The results are in Table 4. We did 2sample t-test between GLYNN with :5dropouts and the strided CNN (resp. GLYNN and GLYNN with :5dropouts) and we found thep-value to be :84(resp :83). So the two CNN (with or without higher dropout) behave pretty much the same. However on the dev set, we found that the higher dropouts tend to do better for Weibo. Effects on changing the training epochs : We also ran Weibo NAM on 20and40epochs but running on 30 epochs gives us the best results. Running Weibo NAM for 20epochs shows a drop in the F1 scores of the LOC tags and thus results in a very poor performance. Losses tend to increase after 30epochs and so the models start doing worse at 40epochs. 30is also an optimum choice for the full Weibo dataset and OntoNotes. We found that running ResumeNER for 20epochs yield better results. Figure 5: GLYNN loss on OntoNotes on various epochs with optimizer Adafactor But we found that lowering the epoch number hurt the performance signiﬁcantly. We also trained all our models with an early stopping if the loss did not decrease over 3 and5epochs as well. That resulted in our models running on OntoNotes to stop around 12and18epochs respectively. Figure 5 shows the relationship between training epochs and loss where the red is the training loss and the blue is the val- idation loss. Figure 6 shows the relation between training epochs of GLYNN and the test and dev F1 scores on Weibo NAM and OntoNotes. How important is the autoencoder : We ran multiple tests (20for Weibo NAM, 10for OntoNotes v 5:0) with varying learning rates and training epochs. We found the autoen- coder improved performance slightly and reduced variance on the dev and test sets. For example, GLYNN with default hyperparameters without the autoencoder got an average test score of 70:98(1:47)on Weibo NAM. Figure 6: Training GLYNN on various epochs on Weibo NAM and OntoNotes v 5:0 5 Conclusion and Future Work Using two very different CNNs with and without an autoen- coder, we have shown gains over the baseline system on the three most commonly used datasets and achieve state of the art F1 score on the Weibo dataset. The novelty of our ap- proach lies in 3salient features: a) very little data to aug- ment our system, b) its easier to train and implement and c) robust. Generating glyph images from text is also not a time consuming process and our models require less glyph data to train. Thus our hope is that using glyphs as an added feature will become a more commonplace occurrence for Chinese NER as it is an easy and quick method to improve the NER systems. We are excited by the future of glyphs in NLP and we would like use glyphs for other NLP tasks. 6 Acknowledgements We would like to thank Johns Hopkins and the SCALE workshop for their hospitality and for facilitating an excel- lent atmosphere for conducting research. We would like to thank Nicholas Andrews for being an excellent mentor and for his continuous support and guidance. We also would like to thank Dawn Lawrie for her mentorship in this project. Finally, we thank Jim Mayﬁeld for preparing the datasets, Derek Zhang for running various experiments, David Etter for the images of the characters, Oyesh Singh and David Mueller for answering our questions. References Ba, J. L.; Kiros, J. R.; and Hinton, G. E. 2016. Layer nor- malization. https:arxiv.orgabs1607.06450. preprint. Che, W.; Wang, M.; Manning, C.; and Ting, L. 2013. Named entity recognition with bilingual constraints. In In Proceed- ings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies , 5262. Atlanta, Georgia: Associ- ation for Computational Linguistics. Chiu, J. P., and Nichols, E. 2016. Named entity recognitionwith bidirectional LSTM-CNNs. Transactions of the Asso- ciation for Computational Linguistics 4:357370. Collobert, R.; Weston, J.; Bottou, L.; Karlen, M.; Kavukcuoglu, K.; and Kuksa, P. 2011. Natural language processing (almost) from scratch. The Journal of Machine Learning Research 24932537. Dai, F. Z., and Cai, Z. 2017. Glyph-aware embedding of chi- nese characters. http:arxiv.orgabs1709.00028. preprint. Devlin, J.; Chang, M.-W.; Lee, K.; and Toutanova, K. 2018. Bert: Pre-training of deep bidirectional transformers for language understanding. https:arxiv.orgabs1810.04805. preprint. Gers, F. A.; Schmidhuber, J.; and Cummins, F. 2000. Learn- ing to forget: Continual prediction with LSTM. Neural Computation 12(10):24512471. Graves, A., and Schmidhuber, J. 2005. Framewise phoneme classiﬁcation with bidirectional lstm and other neural net- work architectures. NEURAL NETWORKS 56. Hammerton, J. 2003. Named entity recognition with long short-term memory. In Proceedings of the Seventh Confer- ence on Natural Language Learning at HLT-NAACL 2003 - Volume 4 , CONLL 03, 172175. Stroudsburg, PA, USA: Association for Computational Linguistics. He, H., and Xu, S. 2017. A uniﬁed model for cross-domain and semi-supervised named entity recognition in Chinese social media. In AAAI Conference on Artiﬁcial Intelligence . Hochreiter, S., and Schmidhuber, J. 1997. Long short-term memory. Neural Comput. 9(8):17351780. Huang, Z.; Xu, W.; and Yu, K. 2015. Bidirectional LSTM- CRF models for sequence tagging. CoRR abs1508.01991. Ioffe, S., and Szegedy, C. 2015. Batch normalization: accel- erating deep network training by reducing internal covari- ate shift. In ICML15 Proceedings of the 32nd International Conference on International Conference on Machine Learn- ing, volume 37, 448456. Li, Y .; Li, W.; Sun, F.; and Li, S. 2015. Component- enhanced Chinese character embeddings. https:arXiv.org abs1508.06669. preprint. Liu, F.; Lu, H.; Lo, C.; and Neubig, G. 2017. Learning character-level compositionality with visual features. https: arxiv.orgabs1704.04859. preprint. Ma, X., and Hovy, E. 2016. End-to-end sequence labeling via bi-directional LSTM-CNNs-CRF. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) , 10641074. Berlin, Germany: Association for Computational Linguistics. Meng, Y .; Wu, W.; Wang, F.; Li, X.; Nie, P.; Yin, F.; Li, M.; Han, Q.; Sun, X.; and Li, J. 2019. Glyce: Glyph-vectors for chinese character representations. http:arxiv.orgabs1901. 10125v3. preprint. Nosirova, N.; Xu, M.; and Jiang, H. 2019. A multi-task learning approach for named entity recognition using local detection. https:arxiv.orgabs1904.03300. Pappu, A.; Blanco, R.; Mehdad, Y .; Stent, A.; and Kapil, T. 2017. Lightweight multilingual entity extraction and link- ing. In In Proceedings of the Tenth ACM International Con- ference on Web Search and Data Mining, WSDM 17 , 365 374. New York, NY , USA: Association for Computational Linguistics. Peng, N., and Dredze, M. 2015. Named entity recognition for Chinese social media with jointly trained embeddings. In Empirical Methods in Natural Language Processing , 548 554. Pradhan, S., and Ramshaw, L. 2017. Ontonotes: Large scale multi-layer, multi-lingual, distributed annotation. In Hand- book of Linguistic Annotation . Springer. 521554. Pradhan, S.; Moschitti, A.; Xue, N.; Ng, H. T.; Bjorkelund, A.; Uryupina, O.; Zhang, Y .; and Zhong, Z. 2013. Towards robust linguistic analysis using ontonotes. In Proceedings of the Seventeenth Conference on Computational Natural Lan- guage Learning . Sang, E. F. T. K., and Meulder, F. D. 2003. Introduction to the conll-2003 shared task: language-independent named entity recognition. In CONLL 03 Proceedings of the seventh conference on Natural language learning at HLT-NAACL 2003 , volume 4, 142147. Shi, X.; Zhai, J.; Yang, X.; Xie, Z.; and Liu, C. 2015. Radi- cal embedding: Delving deeper to Chinese radicals. In In Proceedings of the 53rd Annual Meeting of the Associa- tion for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 2: Short Papers) , 594598. Su, T.-R., and Lee, H.-Y . 2017. Learning Chinese word representations from glyphs of characters. http:arxiv.org abs1708.04755. preprint. Sun, Y .; Lin, L.; Yang, N.; Ji, Z.; and Wang, X. 2014. Radical-enhanced Chinese character embedding. In In In- ternational Conference on Neural Information Processing , 279286. Springer. Xu, M.; Jiang, H.; and Watcharawittayakul, S. 2017. A local detection approach for named entity recognition and men- tion detection. In In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) , 12371247. Vancouver, Canada: Association for Computational Linguistics. Zhang, X., and LeCun, Y . 2017. Which encoding is the best for text classiﬁcation in Chinese, English, Japanese and Korean https:arxiv.orgabs1708.02657. preprint. Zhang, Y ., and Yang, J. 2018. Chinese NER using lattice LSTM. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) , 15541564. Melbourne, Australia: Association for Computational Linguistics. Zhou, Y .; Arpit, D.; Nwogu, I.; and Govindaraju, V . 2015. Is joint training better for deep auto-encoders https:arxiv. orgabs1405.1380. preprint. Zhu, Y ., and Wang, G. 2019. CAN-NER: Convolutional At- tention Network for Chinese Named Entity Recognition. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and ShortPapers) , 33843393. Minneapolis, Minnesota: Association for Computational Linguistics.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "id": "G7I7H_BCorwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importación de bibliotecas y configuración inicial del modelo"
      ],
      "metadata": {
        "id": "f8b9U5oS3JLb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import (load_dataset, DownloadConfig)\n",
        "from transformers import (\n",
        "    LEDTokenizer,\n",
        "    LEDForConditionalGeneration,\n",
        "    Trainer,\n",
        "    TrainingArguments\n",
        ")\n",
        "import os\n",
        "import torch\n",
        "\n",
        "# Desactivar WandB (opcional)\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Parámetros\n",
        "MODEL_NAME = \"allenai/led-base-16384\"\n",
        "MAX_INPUT_LENGTH = 4096  # Para textos largos\n",
        "MAX_TARGET_LENGTH = 300  # Resúmenes más largos (150-300 palabras)\n",
        "BATCH_SIZE = 2\n",
        "EPOCHS = 2\n",
        "LEARNING_RATE = 2e-5\n",
        "\n",
        "# Cargar el tokenizador\n",
        "tokenizer = LEDTokenizer.from_pretrained(MODEL_NAME)\n"
      ],
      "metadata": {
        "id": "EXcfF3Iz3QUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Carga y selección del dataset de entrenamiento\n"
      ],
      "metadata": {
        "id": "_1J1KcA_3Uu-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar en modo de transmisión\n",
        "dataset = load_dataset(\"scientific_papers\", \"pubmed\", split=\"train\", streaming=True, trust_remote_code=True)\n",
        "dataset_test = load_dataset(\"scientific_papers\", \"pubmed\", split=\"test\", streaming=True, trust_remote_code=True)\n",
        "\n",
        "# Seleccionar los primeros 100 ejemplos (mantener el formato de dataset)\n",
        "dataset = dataset.take(100)\n",
        "dataset_test = dataset_test.take(100)"
      ],
      "metadata": {
        "id": "75AP8Xd83Yat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocesamiento del dataset"
      ],
      "metadata": {
        "id": "vJOWJVIt3ex_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocesar datos\n",
        "def preprocess_function(examples):\n",
        "    inputs = examples[\"article\"]\n",
        "    targets = examples[\"abstract\"]\n",
        "\n",
        "    # Convertir a texto si no lo son\n",
        "    inputs = [str(i) for i in inputs]\n",
        "    targets = [str(t) for t in targets]\n",
        "\n",
        "    # Tokenizar las entradas y las etiquetas\n",
        "    model_inputs = tokenizer(\n",
        "        inputs, max_length=MAX_INPUT_LENGTH, truncation=True, padding=\"max_length\"\n",
        "    )\n",
        "    labels = tokenizer(\n",
        "        targets, max_length=MAX_TARGET_LENGTH, truncation=True, padding=\"max_length\"\n",
        "    )\n",
        "\n",
        "    # Añadir las etiquetas como \"labels\"\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n",
        "tokenized_datasets = dataset.map(preprocess_function, batched=True)\n",
        "tokenized_test_datasets = dataset_test.map(preprocess_function, batched=True)\n",
        "\"\"\"\n",
        "# Convertir a listas\n",
        "tokenized_datasets  = list(tokenized_datasets.take(100))\n",
        "ttokenized_test_datasets  = list(tokenized_test_datasets.take(100))\"\"\""
      ],
      "metadata": {
        "id": "ZcpldMqE3feh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "2276a729-ba85-4774-ddd0-9186ccde9572"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# Convertir a listas\\ntokenized_datasets  = list(tokenized_datasets.take(100))\\nttokenized_test_datasets  = list(tokenized_test_datasets.take(100))'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configuración del modelo y entrenamiento\n"
      ],
      "metadata": {
        "id": "F9c5uwx73qUL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar el modelo\n",
        "model = LEDForConditionalGeneration.from_pretrained(MODEL_NAME)\n",
        "model.to(device)\n",
        "# Configuración del entrenamiento\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    per_device_eval_batch_size=BATCH_SIZE,\n",
        "    num_train_epochs=1,\n",
        "    weight_decay=0.01,\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_dir=\"./logs\",\n",
        "    fp16=False,\n",
        "    max_steps=1,  # Establecer un número fijo de pasos para el entrenamiento\n",
        ")\n",
        "\n",
        "# Configurar el Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets,\n",
        "    eval_dataset=tokenized_test_datasets,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "from tqdm import tqdm\n",
        "# Entrenar forzar que se detenga\n",
        "MAX_STEPS = 1\n",
        "# Entrenar con control manual de los pasos\n",
        "for step, batch in enumerate(tqdm(trainer.get_train_dataloader())):\n",
        "    if step >= MAX_STEPS:\n",
        "        break\n",
        "    trainer.training_step(model, batch)\n",
        "# Guardar el modelo\n",
        "model.save_pretrained(\"./trained_model\")\n",
        "tokenizer.save_pretrained(\"./trained_model\")\n",
        "\n"
      ],
      "metadata": {
        "id": "OyOwcOpP3uTK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dde4ff4d-ba89-4ba2-d050-ef319cc40bce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "<ipython-input-24-ac7097fae7bb>:20: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "1it [00:07,  7.32s/it]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./trained_model/tokenizer_config.json',\n",
              " './trained_model/special_tokens_map.json',\n",
              " './trained_model/vocab.json',\n",
              " './trained_model/merges.txt',\n",
              " './trained_model/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Función para resumir textos"
      ],
      "metadata": {
        "id": "FAa4Lq4d30v8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_text(input_text, model, tokenizer):\n",
        "    # Dividir el texto en chunks si es muy largo\n",
        "    def split_text(text, max_length=MAX_INPUT_LENGTH):\n",
        "        tokens = tokenizer.encode(text, truncation=False)\n",
        "        chunks = [tokens[i:i+max_length] for i in range(0, len(tokens), max_length)]\n",
        "        return [tokenizer.decode(chunk, skip_special_tokens=True) for chunk in chunks]\n",
        "\n",
        "    # Tokenizar y procesar el texto\n",
        "    chunks = split_text(input_text)\n",
        "    summaries = []\n",
        "    for chunk in chunks:\n",
        "        inputs = tokenizer(chunk, return_tensors=\"pt\", max_length=MAX_INPUT_LENGTH, truncation=True, padding=True)\n",
        "        summary_ids = model.generate(\n",
        "            inputs[\"input_ids\"],\n",
        "            num_beams=6,\n",
        "            max_length=MAX_TARGET_LENGTH,\n",
        "            min_length=150,\n",
        "            length_penalty=2.0,\n",
        "            repetition_penalty=2.5,\n",
        "            early_stopping=True\n",
        "        )\n",
        "        summaries.append(tokenizer.decode(summary_ids[0], skip_special_tokens=True))\n",
        "\n",
        "    # Combinar los resúmenes parciales\n",
        "    return \" \".join(summaries)\n"
      ],
      "metadata": {
        "id": "RykxPSOa34dj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Modelo de resumen"
      ],
      "metadata": {
        "id": "Wfb7AO094CbQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Aqui la entrada debe ser el texto extraido del pdf\n",
        "#\n",
        "#\n",
        "#\n",
        "# comentar la siguiente linea si se quiere probar con el texto extraido\n",
        "input_text = \"\"\"\n",
        "\"Due to the success of deep learning to solving a variety of challenging machine learning tasks, there is a rising interest in understanding loss functions for training neural networks from a theoretical aspect.\", \"Particularly, the properties of critical points and the landscape around them are of importance to determine the convergence performance of optimization algorithms.\", \"In this paper, we provide a necessary and sufficient characterization of the analytical forms for the critical points (as well as global minimizers) of the square loss functions for linear neural networks.\", \"We show that the analytical forms of the critical points characterize the values of the corresponding loss functions as well as the necessary and sufficient conditions to achieve global minimum.\", \"Furthermore, we exploit the analytical forms of the critical points to characterize the landscape properties for the loss functions of linear neural networks and shallow ReLU networks.\", \"One particular conclusion is that: While the loss function of linear networks has no spurious local minimum, the loss function of one-hidden-layer nonlinear networks with ReLU activation function does have local minimum that is not global minimum.\", \"In the past decade, deep neural networks BID8 have become a popular tool that has successfully solved many challenging tasks in a variety of areas such as machine learning, artificial intelligence, computer vision, and natural language processing, etc.\", \"As the understandings of deep neural networks from different aspects are mostly based on empirical studies, there is a rising need and interest to develop understandings of neural networks from theoretical aspects such as generalization error, representation power, and landscape (also referred to as geometry) properties, etc.\", \"In particular, the landscape properties of loss functions (that are typically nonconex for neural networks) play a central role to determine the iteration path and convergence performance of optimization algorithms.One major landscape property is the nature of critical points, which can possibly be global minima, local minima, saddle points.\", \"There have been intensive efforts in the past into understanding such an issue for various neural networks.\", \"For example, it has been shown that every local minimum of the loss function is also a global minimum for shallow linear networks under the autoencoder setting and invertibility assumptions BID1 and for deep linear networks BID11 ; BID14 ; Yun et al. (2017) respectively under different assumptions.\", \"The conditions on the equivalence between local minimum or critical point and global minimum has also been established for various nonlinear neural networks Yu & Chen (1995) ; BID9 ; BID15 ; BID17 ; BID6 under respective assumptions.However, most previous studies did not provide characterization of analytical forms for critical points of loss functions for neural networks with only very few exceptions.\", \"In BID1 , the authors provided an analytical form for the critical points of the square loss function of shallow linear networks under certain conditions.\", \"Such an analytical form further helps to establish the landscape properties around the critical points.\", \"Further in BID13 , the authors characterized certain sufficient form of critical points for the square loss function of matrix factorization problems and deep linear networks.The focus of this paper is on characterizing the sufficient and necessary forms of critical points for broader scenarios, i.e., shallow and deep linear networks with no assumptions on data matrices and network dimensions, and shallow ReLU networks over certain parameter space.\", \"In particular, such analytical forms of critical points capture the corresponding loss function values and the necessary and sufficient conditions to achieve global minimum.\", \"This further enables us to establish new landscape properties around these critical points for the loss function of these networks under general settings, and provides alternative (yet simpler and more intuitive) proofs for existing understanding of the landscape properties.OUR CONTRIBUTION\", \"1) For the square loss function of linear networks with one hidden layer, we provide a full (necessary and sufficient) characterization of the analytical forms for its critical points and global minimizers.\", \"These results generalize the characterization in BID1 to arbitrary network parameter dimensions and any data matrices.\", \"Such a generalization further enables us to establish the landscape property, i.e., every local minimum is also a global minimum and all other critical points are saddle points, under no assumptions on parameter dimensions and data matrices.\", \"From a technical standpoint, we exploit the analytical forms of critical points to provide a new proof for characterizing the landscape around the critical points under full relaxation of assumptions, where the corresponding approaches in BID1 are not applicable.\", \"As a special case of linear networks, the matrix factorization problem satisfies all these landscape properties.2) For the square loss function of deep linear networks, we establish a full (necessary and sufficient) characterization of the analytical forms for its critical points and global minimizers.\", \"Such characterizations are new and have not been established in the existing art.\", \"Furthermore, such analytical form divides the set of non-global-minimum critical points into different categories.\", \"We identify the directions along which the loss function value decreases for two categories of the critical points, for which our result directly implies the equivalence between the local minimum and the global minimum.\", \"For these cases, our proof generalizes the result in BID11 under no assumptions on the network parameter dimensions and data matrices.3) For the square loss function of one-hidden-layer nonlinear neural networks with ReLU activation function, we provide a full characterization of both the existence and the analytical forms of the critical points in certain types of regions in the parameter space.\", \"Particularly, in the case where there is one hidden unit, our results fully characterize the existence and the analytical forms of the critical points in the entire parameter space.\", \"Such characterization were not provided in previous work on nonlinear neural networks.\", \"Moreover, we apply our results to a concrete example to demonstrate that both local minimum that is not a global minimum and local maximum do exist in such a case.\", \"In this paper, we provide full characterization of the analytical forms of the critical points for the square loss function of three types of neural networks, namely, shallow linear networks, deep linear networks, and shallow ReLU nonlinear networks.\", \"We show that such analytical forms of the critical points have direct implications on the values of the corresponding loss functions, achievement of global minimum, and various landscape properties around these critical points.\", \"As a consequence, the loss function for linear networks has no spurious local minimum, while such point does exist for nonlinear networks with ReLU activation.\", \"In the future, it is interesting to further explore nonlinear neural networks.\", \"In particular, we wish to characterize the analytical form of critical points for deep nonlinear networks and over the full parameter space.\", \"Such results will further facilitate the understanding of the landscape properties around these critical points.\"\n",
        "\"\"\"\n",
        "summary = summarize_text(input_text, model, tokenizer)\n",
        "print(\"Resumen generado:\\n\", summary)"
      ],
      "metadata": {
        "id": "bYVhYNNP4FcN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mejorar gramática."
      ],
      "metadata": {
        "id": "xAxlC39L5YK3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "import language_tool_python\n",
        "\n",
        "# Cargar el modelo para corrección gramatical\n",
        "tool = language_tool_python.LanguageTool('en-US')\n",
        "\n",
        "# Función para corregir errores gramaticales\n",
        "def correct_grammar(text):\n",
        "    matches = tool.check(text)\n",
        "    corrected_text = language_tool_python.utils.correct(text, matches)\n",
        "    return corrected_text\n",
        "\n",
        "# Función para parafrasear el texto (mejorar la coherencia y claridad)\n",
        "def paraphrase_text(text):\n",
        "    # Cargar el modelo de parafraseo\n",
        "    paraphraser = pipeline(\"text2text-generation\", model=\"t5-small\", tokenizer=\"t5-small\")\n",
        "\n",
        "    # Parafrasear el texto\n",
        "    paraphrased = paraphraser(f\"paraphrase: {text}\", max_length=200, num_return_sequences=1)[0]['generated_text']\n",
        "    return paraphrased\n",
        "\n",
        "# Función para mejorar el resumen generado\n",
        "def improve_summary(summary):\n",
        "    # Paso 1: Corregir errores gramaticales\n",
        "    corrected_summary = correct_grammar(summary)\n",
        "\n",
        "    # Paso 2: Parafrasear para mayor coherencia y claridad\n",
        "    improved_summary = paraphrase_text(corrected_summary)\n",
        "\n",
        "    return improved_summary\n",
        "\n",
        "# Ejemplo de resumen generado por el modelo\n",
        "generated_summary = \"Due to the success of deep learning to solving a variety of challenging machine learning tasks, there is a rising interest in understanding loss functions for training neural networks from a theoretical aspect. Particularly, the properties of critical points and the landscape around them are of importance to determine the convergence performance of optimization algorithms.\"\n",
        "\n",
        "# Mejorar el resumen\n",
        "improved_summary = improve_summary(generated_summary)\n",
        "\n",
        "# Mostrar el resumen mejorado\n",
        "print(\"Resumen Mejorado:\")\n",
        "print(improved_summary)\n"
      ],
      "metadata": {
        "id": "R5NsX-S05fjM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelo número dos utilizando t-5 small\n",
        "\n"
      ],
      "metadata": {
        "id": "uBuK9e8RF0g1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration, TrainingArguments, Trainer\n",
        "\n",
        "# Desactivar WandB\n",
        "os.environ[\"WANDB_MODE\"] = \"offline\"\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "# 1. Cargar dataset\n",
        "dataset = load_dataset(\"scientific_papers\", \"pubmed\")\n",
        "\n",
        "# Usar subconjunto pequeño para prueba rápida\n",
        "train_data = dataset[\"train\"].shuffle(seed=42).select(range(2000))\n",
        "val_data = dataset[\"validation\"].shuffle(seed=42).select(range(400))\n",
        "\n",
        "# 2. Cargar modelo y tokenizer\n",
        "model_name = \"t5-small\"\n",
        "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "# 3. Preprocesar datos con estructura\n",
        "def preprocess_data_with_structure(batch):\n",
        "    inputs = [\"summarize with structure: introduction, main topics, conclusion: \" + article for article in batch[\"article\"]]\n",
        "    model_inputs = tokenizer(inputs, max_length=512, truncation=True, padding=\"max_length\")\n",
        "\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(batch[\"abstract\"], max_length=128, truncation=True, padding=\"max_length\")\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n",
        "\n",
        "train_data = train_data.map(preprocess_data_with_structure, batched=True)\n",
        "val_data = val_data.map(preprocess_data_with_structure, batched=True)\n",
        "\n",
        "# 4. Parámetros de entrenamiento\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    num_train_epochs=100,\n",
        "    save_strategy=\"epoch\",\n",
        "    save_total_limit=2,\n",
        "    learning_rate=5e-5,\n",
        "    fp16=True\n",
        ")\n",
        "\n",
        "# 5. Configurar entrenador\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_data,\n",
        "    eval_dataset=val_data,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "# 6. Liberar memoria y entrenar modelo\n",
        "torch.cuda.empty_cache()\n",
        "trainer.train()\n",
        "\n",
        "# 7. Leer archivo .txt y resumir\n",
        "def summarize_text_from_file(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        text = f.read()\n",
        "    return text\n",
        "\n",
        "# Montar Google Drive para acceder al archivo\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Ruta al archivo .txt en Google Drive\n",
        "txt_file_path = \"/content/drive/My Drive/imagenes/output_text_prueba1.txt\"\n",
        "\n",
        "# Leer contenido del archivo\n",
        "text_to_summarize = summarize_text_from_file(txt_file_path)\n",
        "\n",
        "# 8. Generar resumen estructurado\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "inputs = tokenizer(\"summarize with structure: introduction, main topics, conclusion: \" + text_to_summarize,\n",
        "                   max_length=512, truncation=True, return_tensors=\"pt\").to(device)\n",
        "\n",
        "summary_ids = model.generate(\n",
        "    inputs[\"input_ids\"],\n",
        "    max_length=128,\n",
        "    min_length=40,\n",
        "    length_penalty=1.0,\n",
        "    num_beams=4,\n",
        "    early_stopping=True\n",
        ")\n",
        "\n",
        "# Imprimir el resumen estructurado\n",
        "print(\"Resumen Estructurado:\", tokenizer.decode(summary_ids[0], skip_special_tokens=True))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303,
          "referenced_widgets": [
            "3498d4ef5b224d00b0e6b81b4daa2859",
            "2c23079af96f4119ae9bcb24192fce77",
            "61063797fe5342a5aec74e0239bffb87",
            "0b302ba49614409d94408606c62b6fb3",
            "db8737e39c06467c8f3a85ba3662581d",
            "58762e02a6d84beba7b0ee02465ef587",
            "8e32b5cef8bc4a2696f09ac180ad0039",
            "bd741946c0c945e4a9657442e9265d91",
            "3c538542fafe48a8ae3ef06295b1dabc",
            "a74bafa1841b4445a0f26d3759111523",
            "2a04f95b41464f149959b6dd005f1b0d"
          ]
        },
        "id": "-BR2cppeuahb",
        "outputId": "bc7f1f59-1c78-4a07-9224-aad87a9008d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3498d4ef5b224d00b0e6b81b4daa2859"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3953: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "<ipython-input-5-95a31f3fe1f9>:49: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [125/125 26:38, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.841456</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resumen Estructurado: \"there is a rising interest in understanding loss functions for training neural networks from a theoretical aspect,\" he says. \"we exploit the analytical forms of the critical points to characterize the landscape properties for the loss functions of linear neural networks and shallow ReLU networks,\" he says. \"there has been intensive efforts in the past into understanding such an issue for various neural networks,\" he says.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Modelo de traducción de texto\n"
      ],
      "metadata": {
        "id": "nCEV7oNOXciQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "\n",
        "from transformers import MarianTokenizer, MarianMTModel\n",
        "\n",
        "# 1. Cargar el modelo preentrenado y el tokenizador\n",
        "model_name = \"Helsinki-NLP/opus-mt-en-es\"  # Modelo para inglés-español\n",
        "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
        "model = MarianMTModel.from_pretrained(model_name)\n",
        "\n",
        "# 2. Función para traducir texto con mejoras\n",
        "def translate_text(text, model, tokenizer):\n",
        "\n",
        "    # Tokenizar el texto de entrada\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "    # Generar la traducción con parámetros\n",
        "    translated = model.generate(\n",
        "        **inputs,\n",
        "        num_beams=10,  # Explorar más traducciones\n",
        "        early_stopping=True\n",
        "    )\n",
        "\n",
        "    # Decodificar la traducción\n",
        "    translation = tokenizer.decode(translated[0], skip_special_tokens=True)\n",
        "\n",
        "\n",
        "    translation = translation.replace(\" ,\", \",\").replace(\" .\", \".\")\n",
        "    return translation\n",
        "\n",
        "# 3. Probar la traducción\n",
        "sample_text = (\n",
        "    \"there is a rising interest in understanding loss functions for training neural networks from a theoretical aspect, he says. \"\n",
        "    \"we exploit the analytical forms of the critical points to characterize the landscape properties for the loss functions of linear neural networks and shallow ReLU networks, he says. \"\n",
        "    \"there has been intensive efforts in the past into understanding such an issue for various neural networks, he says\"\n",
        ")\n",
        "\n",
        "translated_text = translate_text(sample_text, model, tokenizer)\n",
        "\n",
        "print(\"Texto original:\", sample_text)\n",
        "print(\"Traducción:\", translated_text)"
      ],
      "metadata": {
        "id": "Vd3yZ-F3GPBD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 759,
          "referenced_widgets": [
            "66a2f743e83343168e279ed9161f8ac9",
            "3f5b192ed9f4445b984d66938ea29d62",
            "abfdc76786904da3b30c248e559173d5",
            "013af5390bfc472daa7a1a4bccd78237",
            "320faa92b1404a2c80eeace6df083fe8",
            "dcd2961502124669b5ed0803191ec00a",
            "bb9393c5967e4e0db551a8e89f7703f1",
            "15288f0748c14d64a4b7fc16fb5b6252",
            "bc0da7adc3594ff58d644c771dddb4ec",
            "94c2c9ee194949549fe87e677c20e0bc",
            "247e61a2dd534d82959f8effd17a1b49",
            "77c7dfc0bfac4a428804e6e3cf7fbdeb",
            "0961287606804b71b03d55d9659163b9",
            "26eb8d7f129642efb965b1d6c8218611",
            "8e4929b8b3ef43dda0278500889fa0fb",
            "5b54d7cddd824804bd5afa5268273854",
            "9642289cf36e4e90b47b30a313abb91c",
            "196fe1dd0f17413184cc8f6d95c840bd",
            "605432ea64a0481cac47b633556bc0d2",
            "88c4b0ff48a14c988017e0ae0eaebc5a",
            "f161bcf58937446398a08c7c7760d688",
            "4d55aa77d0a74a63816346d81be4d2e1",
            "05ecfe82f4ec49308725cce4d27ef754",
            "ee764b863ab84b01bf05acf5f5d190ec",
            "35628a9190ae444a9d78a75c2e804bc6",
            "f20c20cc59274a34a8952baeafa87bf7",
            "6d822266d8cb42a392da93e19501036c",
            "742ca5ee2e2c41cf8dbab36ab6e51c3a",
            "172cb2bf30a449839215455b369b23fc",
            "f71d14c3150f4389ab1f754607e1d39f",
            "b246dfc1546847efb036c6f2c88c5bf5",
            "fbe0092fd3cf44d786d2571822fe0a6a",
            "f894a8d8fa384ad094646e7cb89506a7",
            "2c9a1bc005774a08817cf2fd439f3b57",
            "7bbcfb61f8974597a88613b602fa821e",
            "72240e99259b4edda11d30e49fa81b28",
            "25d1c0fc2e0c49128dfd91af67ccf90c",
            "307ff6ab9e0649058f84a5c6461c7b9d",
            "1254f98b9fdb4f0e9f3e2ccd2d8f8b36",
            "e5abe675135841199e64a3a8a31458cd",
            "9f30a8b2bf8b4795a769f810ee1adf5f",
            "9a93379de821475f990f270422cc2021",
            "c0e0f90ef2d84f128c88315ff237bbe9",
            "bbc4d5815ef3464ea2518b9238debb0c",
            "98cc3477e54a44f19b3df2f4ed9b85e6",
            "f2b6da2ea0ef4c4d9abf0588d2a9fb68",
            "f7a6f668a7334bbcb24e350c27d3a666",
            "ff4faecab7364f8b8725367c7139488c",
            "b2ec9a0c13e74f4ea63fc8a3768192b8",
            "e21e07e6603b456aad1699e33967b654",
            "3c1f30178c2f4eea9957596cf317477f",
            "a17b4e26312140e2be2a7cea443d19da",
            "ec15dce1d6364c7183c1979c85659eea",
            "dbf01be89a2c4e21bd7216a28f1d6576",
            "088edc0cb0d942d482a76e1525856f93",
            "4f8d735172e246719c9cf65111531556",
            "7720d097c5aa4def950421319a2cad36",
            "95187b5c8e794697874275805d90f42d",
            "dc61d55d20254121bb6a59ac50a5ca6c",
            "60cc7a26fa5d4a7796a28e961133ed6d",
            "60cb1e913e624324abab7d3303c18484",
            "4157f74be2804e83beccfa5117b660ee",
            "f38be5a866c04da9ab40b107ea64b5f7",
            "8741010dd51f46eeb078b97d1278367e",
            "df7f5d9ef0474b0f99687a08929b0ed3",
            "a6ec715beb76484da71423c12600ff6a",
            "e0ba43159cac424c962b80f532e876e8",
            "3f4e0c2ee5a24db69b79e0c3f1a71b43",
            "d889ffd1fc1c4449bd844907d9adc56c",
            "2e23ff9984f34439a3fb789424d10f04",
            "0c30e87a69954a6eb61baee16e9e3d47",
            "fc09dc1815c24ff797386dab5c68ff63",
            "e505a2344ad344c2ba877c699d328e81",
            "3e3ecffe468a42a9842fba6afc6e3f29",
            "409905e1b84d43b38af6ad09d1503507",
            "c9f2464d91ad4490b213899e3624fab3",
            "c691132db5c74ad0a60b3d34362ef33d"
          ]
        },
        "outputId": "34a5d239-d835-4e35-d371-97441be391fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/44.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "66a2f743e83343168e279ed9161f8ac9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "source.spm:   0%|          | 0.00/802k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "77c7dfc0bfac4a428804e6e3cf7fbdeb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "target.spm:   0%|          | 0.00/826k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "05ecfe82f4ec49308725cce4d27ef754"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.59M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2c9a1bc005774a08817cf2fd439f3b57"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.47k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "98cc3477e54a44f19b3df2f4ed9b85e6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
            "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/312M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4f8d735172e246719c9cf65111531556"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e0ba43159cac424c962b80f532e876e8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Texto original: there is a rising interest in understanding loss functions for training neural networks from a theoretical aspect, he says. we exploit the analytical forms of the critical points to characterize the landscape properties for the loss functions of linear neural networks and shallow ReLU networks, he says. there has been intensive efforts in the past into understanding such an issue for various neural networks, he says\n",
            "Traducción: Hay un interés creciente en entender las funciones de pérdida para el entrenamiento de redes neuronales desde un aspecto teórico, dice. explotamos las formas analíticas de los puntos críticos para caracterizar las propiedades del paisaje para las funciones de pérdida de redes neuronales lineales y redes ReLU poco profundas, dice. ha habido esfuerzos intensivos en el pasado para entender tal problema para varias redes neuronales, dice.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Modelo 2 de Traducción de Texto con Transformer\n"
      ],
      "metadata": {
        "id": "vDxF5Kz3QSs8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras_transformer import get_model, decode\n",
        "from pickle import load\n",
        "\n",
        "# Funciones\n",
        "def build_token_dict(token_list):\n",
        "    token_dict = {'<PAD>': 0, '<START>': 1, '<END>': 2}\n",
        "    for tokens in token_list:\n",
        "        for token in tokens:\n",
        "            if token not in token_dict:\n",
        "                token_dict[token] = len(token_dict)\n",
        "    return token_dict\n",
        "\n",
        "def translate(sentence, model, source_token_dict, target_token_dict, target_token_dict_inv):\n",
        "    sentence_tokens = [['<START>'] + sentence.split(' ') + ['<END>']]\n",
        "    tr_input = [list(map(lambda x: source_token_dict.get(x, source_token_dict['<PAD>']), tokens)) for tokens in sentence_tokens][0]\n",
        "\n",
        "    decoded = decode(\n",
        "        model,\n",
        "        tr_input,\n",
        "        start_token=target_token_dict['<START>'],\n",
        "        end_token=target_token_dict['<END>'],\n",
        "        pad_token=target_token_dict['<PAD>']\n",
        "    )\n",
        "\n",
        "    print('Frase original:', sentence)\n",
        "    print('Traducción:', ' '.join(map(lambda x: target_token_dict_inv[x], decoded[1:-1])))\n",
        "\n",
        "# Configuración inicial\n",
        "filename = 'B:/UPIIT/I.A. UPIIT/6to_Semestre/LenguajeNatural/Parcial 3/Proyectos/traductor/codigos ocupados/dataset_Completo.csv'\n",
        "np.random.seed(0)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Cargar el dataset\n",
        "    dataset = pd.read_csv(filename)\n",
        "    print(dataset.iloc[383015, 0])\n",
        "    print(dataset.iloc[383015, 1])\n",
        "\n",
        "    # Tokenización\n",
        "    source_tokens = [sentence.split(' ') for sentence in dataset['english']]\n",
        "    target_tokens = [sentence.split(' ') for sentence in dataset['spanish']]\n",
        "    print(source_tokens[383015])\n",
        "    print(target_tokens[383015])\n",
        "\n",
        "    # Construcción de diccionarios\n",
        "    source_token_dict = build_token_dict(source_tokens)\n",
        "    target_token_dict = build_token_dict(target_tokens)\n",
        "    target_token_dict_inv = {v: k for k, v in target_token_dict.items()}\n",
        "\n",
        "    # Preparar datos para el modelo\n",
        "    encoder_tokens = [['<START>'] + tokens + ['<END>'] for tokens in source_tokens]\n",
        "    decoder_tokens = [['<START>'] + tokens + ['<END>'] for tokens in target_tokens]\n",
        "    output_tokens = [tokens + ['<END>'] for tokens in target_tokens]\n",
        "\n",
        "    source_max_len = max(map(len, encoder_tokens))\n",
        "    target_max_len = max(map(len, decoder_tokens))\n",
        "\n",
        "    encoder_tokens = [tokens + ['<PAD>'] * (source_max_len - len(tokens)) for tokens in encoder_tokens]\n",
        "    decoder_tokens = [tokens + ['<PAD>'] * (target_max_len - len(tokens)) for tokens in decoder_tokens]\n",
        "    output_tokens = [tokens + ['<PAD>'] * (target_max_len - len(tokens)) for tokens in output_tokens]\n",
        "\n",
        "    encoder_input = [list(map(lambda x: source_token_dict[x], tokens)) for tokens in encoder_tokens]\n",
        "    decoder_input = [list(map(lambda x: target_token_dict[x], tokens)) for tokens in decoder_tokens]\n",
        "    output_decoded = [list(map(lambda x: [target_token_dict[x]], tokens)) for tokens in output_tokens]\n",
        "\n",
        "    # Crear y entrenar el modelo\n",
        "    model = get_model(\n",
        "        token_num=max(len(source_token_dict), len(target_token_dict)),\n",
        "        embed_dim=32,\n",
        "        encoder_num=2,\n",
        "        decoder_num=2,\n",
        "        head_num=4,\n",
        "        hidden_dim=128,\n",
        "        dropout_rate=0.1,\n",
        "        use_same_embed=False,\n",
        "    )\n",
        "    model.compile('adam', 'sparse_categorical_crossentropy')\n",
        "    model.summary()\n",
        "\n",
        "    x = [np.array(encoder_input), np.array(decoder_input)]\n",
        "    y = np.array(output_decoded)\n",
        "\n",
        "    #Quitar como comentarios solo si se quiere entrenar el modelo:\n",
        "    #history = model.fit(x, y, epochs=100, batch_size=32)\n",
        "    #print(history.history)\n",
        "    #model.save('translator_trained.h5')\n",
        "    filename = '/content/drive/My Drive/translator_trained.h5'\n",
        "    model.load_weights(filename)\n",
        "\n",
        "    # Traducción\n",
        "    translate('Yes I am.', model, source_token_dict, target_token_dict, target_token_dict_inv)\n"
      ],
      "metadata": {
        "id": "Z9mFCqPaQUrI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "    translate('there is a rising interest in understanding loss functions for training neural networks from a theoretical aspect, he says we exploit the analytical forms of the critical points to characterize the landscape properties for the loss functions of linear neural networks and shallow ReLU networks, he says. there has been intensive efforts in the past into understanding such an issue for various neural networks, he says', model, source_token_dict, target_token_dict, target_token_dict_inv)"
      ],
      "metadata": {
        "id": "zOUMCBMTQXCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Modelo utilizando lecturas con caracteres matemáticos\n",
        "\n"
      ],
      "metadata": {
        "id": "kdvqb3nbljxS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade fsspec gcsfs\n",
        "!pip install transformers datasets\n",
        "\n",
        "import os\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration, TrainingArguments, Trainer\n",
        "from google.colab import drive\n",
        "\n",
        "# Montar Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "os.environ[\"WANDB_MODE\"] = \"offline\"  # disable\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "# Configurar PYTORCH_CUDA_ALLOC_CONF\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
        "\n",
        "# 1. Cargar dataset de arXiv (papers que contienen fórmulas y números)\n",
        "dataset = load_dataset(\"scientific_papers\", \"arxiv\")\n",
        "\n",
        "# Usar subconjunto pequeño para prueba rápida\n",
        "train_data = dataset[\"train\"].shuffle(seed=42).select(range(500))\n",
        "val_data = dataset[\"validation\"].shuffle(seed=42).select(range(200))\n",
        "\n",
        "# 2. Cargar modelo y tokenizer\n",
        "model_name = \"t5-small\"  # Usa t5-small para menor uso de memoria\n",
        "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "# 3. Preprocesar datos\n",
        "def preprocess_data(batch):\n",
        "    inputs = [\"summarize: \" + article for article in batch[\"article\"]]\n",
        "    model_inputs = tokenizer(inputs, max_length=512, truncation=True, padding=\"max_length\")\n",
        "\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(batch[\"abstract\"], max_length=128, truncation=True, padding=\"max_length\")\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n",
        "\n",
        "train_data = train_data.map(preprocess_data, batched=True)\n",
        "val_data = val_data.map(preprocess_data, batched=True)\n",
        "\n",
        "# 4. Parámetros de entrenamiento\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    per_device_train_batch_size=4,  # Reducir tamaño del lote\n",
        "    per_device_eval_batch_size=4,  # Reducir tamaño del lote\n",
        "    num_train_epochs=2,\n",
        "    save_strategy=\"epoch\",\n",
        "    save_total_limit=2,\n",
        "    learning_rate=5e-5,\n",
        "    fp16=True\n",
        ")\n",
        "\n",
        "# 5. Configurar entrenador\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_data,\n",
        "    eval_dataset=val_data,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "# 6. Liberar memoria y entrenar modelo\n",
        "torch.cuda.empty_cache()\n",
        "trainer.train()\n",
        "\n",
        "# 7. Leer archivo .txt desde Google Drive y resumir\n",
        "def summarize_text_from_file(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        text = f.read()\n",
        "    return text\n",
        "\n",
        "# Ruta al archivo .txt en Google Drive\n",
        "txt_file_path = \"/content/drive/My Drive/imagenes/output_text_prueba2.txt\"\n",
        "\n",
        "# Leer contenido del archivo\n",
        "text_to_summarize = summarize_text_from_file(txt_file_path)\n",
        "\n",
        "# 8. Generar resumen estructurado\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "inputs = tokenizer(\"summarize: \" + text_to_summarize, max_length=512, truncation=True, return_tensors=\"pt\").to(device)\n",
        "summary_ids = model.generate(inputs[\"input_ids\"], max_length=128, min_length=30, length_penalty=2.0, num_beams=4)\n",
        "\n",
        "print(\"Resumen:\", tokenizer.decode(summary_ids[0], skip_special_tokens=True))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f71f5ece040248aa8b0d7df0250513c9",
            "01686a4dd78a4defb5e58afac15789c2",
            "1ba419bf100d4320ba4f74665230b552",
            "a3fc7ad0bdac4f80ae1eeb13778fa246",
            "45f3396f3b7c4bf6a6c3a01a6fc59a5e",
            "a921fb796e654816adee709d63ba6092",
            "f893ceb86906464897ae56086527ba1b",
            "6ca5969d219e485cb0c7c2138b8e65e4",
            "e2a84a7e2c784f8e818a05eb7e4789bc",
            "2db2b508dd3845448169d4ead9ebd7f6",
            "40b57c6694374672919e1e410e8f38c1"
          ]
        },
        "id": "rpOoFXLda1XB",
        "outputId": "a1350e25-d40a-449f-f0de-d79b39608c99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (2024.9.0)\n",
            "Collecting fsspec\n",
            "  Using cached fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: gcsfs in /usr/local/lib/python3.10/dist-packages (2024.12.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from gcsfs) (3.11.10)\n",
            "Requirement already satisfied: decorator>4.1.2 in /usr/local/lib/python3.10/dist-packages (from gcsfs) (4.4.2)\n",
            "Requirement already satisfied: google-auth>=1.2 in /usr/local/lib/python3.10/dist-packages (from gcsfs) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.10/dist-packages (from gcsfs) (1.2.1)\n",
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.10/dist-packages (from gcsfs) (2.19.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from gcsfs) (2.32.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (1.18.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.2->gcsfs) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.2->gcsfs) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.2->gcsfs) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib->gcsfs) (1.3.1)\n",
            "Requirement already satisfied: google-api-core<3.0.0dev,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage->gcsfs) (2.19.2)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage->gcsfs) (2.4.1)\n",
            "Requirement already satisfied: google-resumable-media>=2.7.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage->gcsfs) (2.7.2)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage->gcsfs) (1.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->gcsfs) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->gcsfs) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->gcsfs) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->gcsfs) (2024.12.14)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->gcsfs) (1.66.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->gcsfs) (4.25.5)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->gcsfs) (1.25.0)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (4.12.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2->gcsfs) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs) (3.2.2)\n",
            "Using cached fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "Installing collected packages: fsspec\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.9.0\n",
            "    Uninstalling fsspec-2024.9.0:\n",
            "      Successfully uninstalled fsspec-2024.9.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datasets 3.2.0 requires fsspec[http]<=2024.9.0,>=2023.1.0, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed fsspec-2024.12.0\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Using cached fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.10)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Using cached fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "Installing collected packages: fsspec\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.12.0\n",
            "    Uninstalling fsspec-2024.12.0:\n",
            "      Successfully uninstalled fsspec-2024.12.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.12.0 requires fsspec==2024.12.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed fsspec-2024.9.0\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f71f5ece040248aa8b0d7df0250513c9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "<ipython-input-7-959e02a40550>:58: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [250/250 49:35, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.271149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.198559</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resumen: Derivada de una constante por una funcién f(x) =u+tv f(x)=ultv' Derivada de una constante por una funcién f(x)=keu f(x)=keu' Derivada de una raiz cuadrada f(x) = k Kigk-1 Ejemplos de derivadas F(x) =-2 f(x\n"
          ]
        }
      ]
    }
  ]
}